\documentclass[10pt]{article}

\usepackage{mathtools, amssymb, bm}
\usepackage{microtype}
\usepackage[utf8]{inputenc}
\usepackage[margin = 1in]{geometry}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{tikzsymbols}
\usepackage[hidelinks]{hyperref}
\usepackage{titlesec}



% \titleformat{\section}{\normalsize\bfseries}{\thesection}{1em}{}
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\setcounter{secnumdepth}{0}

\definecolor{colabcol}{HTML}{960018}
\newcommand{\mycolab}[1]{\textcolor{colabcol}{\textsl{Collaborators:}} #1 \\ }
\newcommand{\mycolaba}[1]{\textcolor{colabcol}{\textsl{Collaborators:}} #1}

\title{
    {\Large Homework 1}
}
\author{
    {\normalsize Aiden Kenny}\\
    {\normalsize STAT GR5204: Statistical Inference}\\
    {\normalsize Columbia University}
}
\date{\normalsize November 10, 2020}

\begin{document}

\maketitle

%' ============================================================================================================================================================
\section{Question 1} \noindent
When rolling two dice, there are six possible ways for their total to sum up to seven: \((1,6)\), \((2,5)\), \((3,4)\), \((4,3)\), \((5,2)\), and \((6,1)\), 
so the probability of the sum being seven is \(6 / 36 = 1 / 6\). If \(X\) is the number of trials where the total of both rolls is seven, then we can think 
of \(X \sim \mathrm{Bin}(120, 1/6)\), and so \(\mathbb{E}X = 20\) and \(\mathrm{Var}X = 50 / 3\). 
% Then the random variable 
% \(Z = \frac{X - 20}{\sqrt{5/36}} \sim \mathrm{N}(0, 1)\)
% Note then that \(\sqrt{\mathrm{Var}X / n} = \sqrt{5}/6\).
Using the Central Limit Theorem, we then have 
\begin{align*}
    \mathrm{Pr}\big( |X - 20| \le k \big)
    = \mathrm{Pr} \left( \left| \frac{X - 20}{\sqrt{50/3}} \right| \le k \sqrt{\frac{3}{50}} \right)
    = 2 \Phi \left( k \sqrt{\frac{3}{50}} \right) - 1
    \overset{\text{set}}{=} 0.95
    ~~\Longrightarrow~~ \Phi \left( k \sqrt{\frac{3}{50}} \right) = 0.975.
\end{align*}
Using a table of values for \(\Phi(z)\), we can see that \(k \sqrt{3 / 50} = 1.96\), and so \(k = 1.96 \sqrt{50/3} \approx 8\).

%' ============================================================================================================================================================
\section{Question 2} \noindent
Let \(X \sim \mathrm{Pois}(10)\), and so \(\mathbb{E}X = \mathrm{Var}X = 10\). Using the CLT without any continuity correction, we have 
\((X - 10)/\sqrt{10} \approx \mathrm{N}(0,1)\), and so 
\begin{align*}
    \mathrm{Pr}(8 \le X \le 12)
    % = \mathrm{Pr} \left( \frac{8 - 10}{\sqrt{10}} \le \frac{X - 10}{\sqrt{10}} \le \frac{12 - 10}{\sqrt{10}} \right)
    = \mathrm{Pr} \left( \frac{8 - 10}{\sqrt{10}} \le Z \le \frac{12 - 10}{\sqrt{10}} \right)
    % = \mathrm{Pr} \big(- \sqrt{2 / 5} \le Z \le \sqrt{2 / 5} \big) \\
    = \mathrm{Pr} \big( |Z| \le \sqrt{2/5} \big) 
    % &\approx \Phi \big( \sqrt{2/5} \big) - \Phi \big( -\sqrt{2/5} \big)
    \approx 2 \Phi \big( \sqrt{2/5} \big) - 1 
    = 0.4714.
\end{align*}
If we do use continuity correction, then we have 
\begin{align*}
    \mathrm{Pr}(8 \le X \le 12)
    &\approx \mathrm{Pr}(7.5 \le X \le 12.5) \\
    &= \mathrm{Pr} \left( \frac{7.5 - 10}{\sqrt{10}} \le Z \le \frac{12.5 - 10}{\sqrt{10}} \right)
    = \mathrm{Pr} \big( |Z| \le 2.5/\sqrt{10} \big) 
    \approx 2 \Phi \big( 2.5/\sqrt{10} \big) - 1 
    = 0.5704.
\end{align*}
% The exact probability can be found as 
% \begin{align*}
%     \mathrm{Pr}(8 \le X \le 12)
%     = \sum_{x = 8}^{12} \frac{10^x \mathrm{e}^{-10}}{x!}
%     = 
% \end{align*}
% so the continuity correction significantly improves the accuracy of our estimation.

%' ============================================================================================================================================================
\section{Question 3} \noindent
We are assuming that when a program is run, an execution error will occur with probability \(\theta \in [0,1]\). If \(X\) is whether or not an execution error
occurs, we have \(X \sim \mathrm{Ber}(\theta)\), and \(f(x \,|\, \theta) = \theta^x (1 - \theta)^{1 - x}\) for \(x = \{0,1\}\). We also believe that 
\(\theta \sim \mathrm{Unif}(0,1)\), and so \(\xi(\theta) = 1\) for \(0 \le \theta \le 1\).
\begin{itemize}
    \item[(a)] After 25 runs of the program we have 10 erros, so \(f(\mathbf{x} \,|\, \theta) = \theta^{10}(1 - \theta)^{15}\). The marginal distribution of 
    \(\mathbf{x}\) is given by 
    \begin{align*}
        g_{\bm{X}}(\mathbf{x})
        = \int_{\Omega} f(\mathbf{x} \,|\, \theta) \cdot \xi(\theta) \;\mathrm{d}\theta 
        = \int_0^1 \theta^{10} (1 - \theta)^{15} \cdot 1 \;\mathrm{d}\theta
        = \int_0^1 \theta^{11 - 1} (1 - \theta)^{16 - 1} \;\mathrm{d}\theta
        = \mathrm{B}(11, 16),
    \end{align*}
    and so the posterior pdf of \(\theta\) is 
    \begin{align*}
        \xi(\theta \,|\, \mathbf{x})
        = \frac{f(\mathbf{x} \,|\, \theta) \cdot \xi(\theta)}{g_{\bm{X}}(\mathbf{x})}
        = \frac{\theta^{10} (1 - \theta)^{15} \cdot 1}{\mathrm{B}(11, 16)}
        = \frac{\theta^{11 - 1} (1 - \theta)^{16 - 1}}{\mathrm{B}(11, 16)}.
    \end{align*}
    That is, \(\theta \sim \mathrm{Beta}(11, 16)\). 
    \item[(b)] If we are using squared error loss, then our Bayes' estimate would be 
    \(\hat{\theta} = \mathbb{E}(\theta \,|\, \mathbf{x}) = 11/(11 + 16) = 11/27\).
\end{itemize}

%' ============================================================================================================================================================
\section{Question 4} \noindent
We believe that \(\theta \sim \mathrm{Beta}(3, 4)\), where \(\theta \in [0,1]\) is the proportion of bad apples in the lot. 
% For each pick, if \(X \in \{0,1\}\) denotes whether or not a bad apple was chosen, we have \(f(x \,|\, \theta) = \theta^x (1 - \theta)^{1 - x}\)
% After randomly choosing 10 applies, we find that three of them are bad, so our posterior 
% Since choosing apples and determining whether or not it is bad is sampling from a Bernoulli distribution
Choosing apples from the lot is essentially sampling from a Bernoulli distribution with parameter \(\theta\),
and we know that Beta distributions are closed under sampling from a Bernoulli distribution. After choosing 
10 apples, we find that three of them are bad, so our posterior distribution becomes \(\theta \sim \mathrm{Beta}(3+3, 4+7) = \mathrm{Beta}(6,11)\).
If we use squared error loss, our Bayes' estimate is then \(\delta^*(\mathbf{x}) = \mathbb{E}(\theta \,|\, \mathbf{x}) = 6 / 17\).

\end{document}